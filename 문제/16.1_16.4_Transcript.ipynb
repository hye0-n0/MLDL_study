{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"grUQdWnOWlm8"},"source":["# Transformer의 깊은 이해\n","트랜스포머를 로우레벨부터 구현해보도록 하겠습니다.  \n","트랜스포머를 한층 한층 직접 쌓아보이시면 추후에 트랜스포머 계열들을 쉽게 이해하실 수 있습니다.  \n","**나중에 계속 트랜스 포머 계열인 Bert, XLnet, ALBERT, Reformer 등을 공부하시면서 어려움에 봉착할 때마다 만성적으로 고민하며 시간을 날리는 것보다는, 지금 한번 제대로 이해하시면 훗날 크게 도움이 될 것이라 믿습니다.**  \n","\n","https://www.tensorflow.org/tutorials/text/transformer 를 쉽게 구현하고 이해할 수 있도록 코드를 약간 수정하였습니다.  \n","포르투갈어를 영어로 번역하는 Seq2Seq 예제를 통해서 트랜스포머에 익숙해져 보기로 하겠습니다.  \n","\n","직관적인 설명은 이 사이트에 더 잘 되어 있으며, 저는 직접 실행해보는 관점에서 설명드리고자 합니다. 시각적 설명을 원하시면 이 사이트에 접속하시기 바랍니다.\n","http://jalammar.github.io/illustrated-transformer/  \n","이번 강의에서는 **포르투갈어를 영어로 바꾸는 Seq2Seq** 문제를 **Transformer를 활용하여 해결해 보도록 하겠습니다.**  \n","![Imgur](https://i.imgur.com/Z0QOeAG.png)"]},{"cell_type":"markdown","metadata":{"id":"WRvYAI5bn4dF"},"source":["# 데이터 로드\n","데이터 로드는 tensorflow 2에서 제공하는 tf.data.dataset 형식으로 로드하도록 하겠습니다. dataset 형식으로 데이터를 불러오면, 향후 모델을 훈련시킬 때 @tf.function 데코레이터를 활용하여 상당히 빠르게 학습할 수 있습니다."]},{"cell_type":"code","source":["# Install the most re version of TensorFlow to use the improved\n","# masking support for `tf.keras.layers.MultiHeadAttention`.\n","!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n","!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n","!pip install -q tensorflow_datasets\n","!pip install -q -U tensorflow-text tensorflow"],"metadata":{"id":"nJYOSWjur5ng","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675743201729,"user_tz":-540,"elapsed":165176,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"2555d784-ab4a-4464-81c6-01e85870a0c4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-510\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be DOWNGRADED:\n","  libcudnn8\n","0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 25 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 1,392 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 19s (23.2 MB/s)\n","(Reading database ... 129496 files and directories currently installed.)\n","Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n","update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n","\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n","(Reading database ... 129473 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n","\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","metadata":{"id":"C42H5OZMmJL1","executionInfo":{"status":"ok","timestamp":1675743257521,"user_tz":-540,"elapsed":2244,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["# 포르투갈어-프랑스어 데이터 로드를 위한 임포트\n","import tensorflow_datasets as tfds"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFNmJRi0YQ26","executionInfo":{"status":"ok","timestamp":1675743259286,"user_tz":-540,"elapsed":1770,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["# 분석에 필요한 모듈 임포트\n","import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cv7qcd-GmMNY","executionInfo":{"status":"ok","timestamp":1675743372657,"user_tz":-540,"elapsed":1246,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["# 데이터 불러오기\n","examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n","                               as_supervised=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLUAtajEmkBN"},"source":["# 데이터가 test, train, validation에 있음\n","# 이 데이터들의 형식은 tf.data.dataset 오브젝트\n","examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_sP_h17ApCwY"},"source":["type(examples['train'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YoSV2XmmSs2","executionInfo":{"status":"ok","timestamp":1675743383949,"user_tz":-540,"elapsed":1183,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["# train, validation, test 데이터로 나누기\n","train_examples, val_examples, test_examples = examples['train'], examples['validation'], examples['test']"],"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 시간이 좀 걸리는데 정상입니다.\n","# train_example 에는 포르투갈어 pt, 영어 en이 있음\n","# 여기서 단어를 추출해서, 단어들마다 인덱싱을 부여할 것임\n","# 인덱싱을 부여하는 클래스가 tokenizer_en(영어 인덱싱 부여), tokenizer_pt(포르투갈어 인덱싱 부여)\n","\n","tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n","\n","tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n","    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"],"metadata":{"id":"UTozzBWgsCTz","executionInfo":{"status":"ok","timestamp":1675743563129,"user_tz":-540,"elapsed":24366,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"VOGyn1FCqLXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675743704035,"user_tz":-540,"elapsed":7,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"98aca577-ab56-48f7-d520-145fad1e61c6"},"source":["# 영어를 인코딩\n","tokenizer_en.encode(\"Hello man, Let's run transformer!\")"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[7903, 2429, 439, 406, 7345, 7907, 1283, 7870, 9, 527, 6514, 7945, 7864]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ZhMCauShqWkx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675743707823,"user_tz":-540,"elapsed":7,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"dd98b6ab-993e-4a45-fa78-68f0ba9ebff7"},"source":["# 포르투갈어를 인코딩\n","print(tokenizer_pt.encode(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\"))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[141, 77, 33, 1566, 873, 4501, 217, 642, 4, 217, 101, 1073, 4824, 17, 5, 488, 200, 8004]\n"]}]},{"cell_type":"code","source":["def encode(lang1, lang2):\n","\n","  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n","      lang1.numpy()) + [tokenizer_pt.vocab_size+1] # 포르투갈 어를 인코딩 할 때 시작 단어를 의미하는 숫자와, 끝 단어를 의미하는 숫자가 붙음\n","  \n","  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n","      lang2.numpy()) + [tokenizer_en.vocab_size+1] # 영어도 마찬가지임\n","\n","  return lang1, lang2"],"metadata":{"id":"U5wAt2KCG3wt","executionInfo":{"status":"ok","timestamp":1675744291471,"user_tz":-540,"elapsed":3,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"34DVDfJ0sR6y","executionInfo":{"status":"ok","timestamp":1675744294602,"user_tz":-540,"elapsed":6,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["lang1 = tf.constant(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\", dtype=tf.string)\n","lang2 = tf.constant(\"Hello man, Let's run transformer!\", dtype=tf.string)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nlm39twMrCKb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675744297685,"user_tz":-540,"elapsed":6,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"9d5bada1-7356-4705-e01a-8e748a458061"},"source":["print(encode(lang1, lang2))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["([8214, 141, 77, 33, 1566, 873, 4501, 217, 642, 4, 217, 101, 1073, 4824, 17, 5, 488, 200, 8004, 8215], [8087, 7903, 2429, 439, 406, 7345, 7907, 1283, 7870, 9, 527, 6514, 7945, 7864, 8088])\n"]}]},{"cell_type":"code","source":["# tf.py_function을 활용하여 모든 문장에 숫자를 부여함\n","\n","def tf_encode(pt, en):\n","  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64]) # 인풋 값으로 pt와 en이 한문장 한문장씩 들어가서 result_pt, result_en을 아웃풋으로 내게 됨\n","  result_pt.set_shape([None])\n","  result_en.set_shape([None])\n","  return result_pt, result_en"],"metadata":{"id":"nlZjwzWWJOyY","executionInfo":{"status":"ok","timestamp":1675744420624,"user_tz":-540,"elapsed":929,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["MAX_LENGTH = 40\n","BUFFER_SIZE = 60000\n","BATCH_SIZE = 64\n","\n","# 전체 데이터에서 x가 포르투갈어 한 문장, y가 영어 한 문장인데\n","# 만약 문장이 인코딩 되었을 때, 인코딩 된 길이가 40을 초과하면 데이터에서 배제하고자 하는 필터 함수임\n","def filter_max_length(x, y, max_length=MAX_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)"],"metadata":{"id":"eZUyla0aJrPL","executionInfo":{"status":"ok","timestamp":1675744454001,"user_tz":-540,"elapsed":1197,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"V83U1EEQtGA-","executionInfo":{"status":"ok","timestamp":1675744971740,"user_tz":-540,"elapsed":1231,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["train_dataset = train_examples.map(tf_encode) # tf_encode 함수를 활용해서 포르투갈어, 영어 각 문장에 시작 토큰과 끝 토큰을 부여함\n","train_dataset = train_dataset.filter(filter_max_length) # 문장의 길이가 40이 넘는 문장은 배제하고자 함\n","# cache the dataset to memory to get a speedup while reading from it.\n","train_dataset = train_dataset.cache() # cache를 활용해서 데이터를 로드할 때 빠른 처리를 기대해 봄\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE) \n","# shuffle(60000) 인데, 이 말은 전체 데이터를 완전히 섞겠다는 뜻임\n","# 전체 데이터의 수가 50000인데 50000보다 큰 숫자를 입력하면 완전하게 전체 데이터를 섞는 것이며\n","# 전체 데이터 수보다 작은 수를 입력하면 전체 데이터에서 일부만 섞음\n","# padded_batch는 무엇이냐면, 이번 데이터셋은 문장마다 길이가 모두 다르기에\n","# 배치 사이즈(32) 만큼의 문장을 뽑을 때마다\n","# 배치 사이즈에 해당하는 만큼의 문장의 길이는 일정하게 유지됨\n","# 무슨 말이냐면 배치가 2개라면  이 중 하나의 문장의 길이는 37이 될 수 있고\n","# 두 개의 배치(32) 중 하나의 배치는 문장의 길이를 37개로 모두 유지\n","# 그 다음 배치에서 문장의 길이가 39 라면, 그 배치에서는 문장의 길이를 39로 유지\n","                                                                            \n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE) # 데이터 로드와 처리의 시간을 overlap하여 속도 향상\n","\n","val_dataset = val_examples.map(tf_encode)\n","val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE) #가변길이의 배치를 돌릴때 꼭 쓰자"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Wxi5ftvtRNr"},"source":["#트랜스포머 구조\n","트랜스포머 트랜스포머의 구조는 \n","1. (위치 + 단어 임베딩) -> 2, 인코더 3. 디코더로 나뉩니다.  \n","\n","먼저 임베딩부터 살펴보도록 하겠습니다.\n","\n","![Imgur](https://i.imgur.com/Tl2zsFL.png)"]},{"cell_type":"markdown","metadata":{"id":"bkpvhCMnsVAm"},"source":["#임베딩 파트 정의\n","트랜스포머는 단어 임베딩 + 위치 임베딩, 두 가지 임베딩을 거치게 되며  \n","단어 임베딩은 많이 해봤기 때문에, 위치 임베딩만 살펴 보도록 하겠습니다.  \n","**왜 위치 임베딩을 하나면 RNN 계열 같이 문장 내부 단어의 순서를 나타낼 방법이 없기 때문입니다.**  \n","같은 단어라도 위치 임베딩 때문에 순서에 따라서 단어가 임베딩 된 것은 다를 수 있습니다.  \n","![Imgur](https://i.imgur.com/sSnVRpY.png)"]},{"cell_type":"markdown","metadata":{"id":"bZzxZS6Eym3W"},"source":["![Imgur](https://i.imgur.com/SNIEhlA.png)"]},{"cell_type":"code","metadata":{"id":"v5cFMcfBymSE","executionInfo":{"status":"ok","timestamp":1675746243748,"user_tz":-540,"elapsed":1026,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["# 먼저 포지셔널 임베딩부터\n","# pos / 10000 ** (2i / d_model)에 해당하는 부분을\n","# get_angles 함수로 출력하기\n","\n","def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i // 2) / np.float32(d_model)))\n","    # shape = (1, d_model)\n","  return np.matmul(pos, angle_rates) # pos shape : (pos, 1), angle_rates shape = (1, d_model),\n","                                     # np.matmul(pos, angle_rates) shape : 행렬곱 (pos,1), (1, d_model) = (pos, d_model)\n","\n","def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model) # shape : (position, d_model)\n","  # 오른쪽으로 짝수번째 인덱스는 sin 함수를 적용\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  # 오른쪽으로 홀수번째 인덱스는 cos 함수를 적용\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","  pos_encoding = angle_rads[np.newaxis, ...] # pos_encoding shape : (1, position, d_model)\n","                                             # 왜 shape에 1을 추가해주냐면, batch_size 만큼 학습하기 위함임\n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"va41MjAM-67o","outputId":"4d9478fe-0642-492b-ac85-32b1f3743745","colab":{"base_uri":"https://localhost:8080/","height":301},"executionInfo":{"status":"ok","timestamp":1675746348099,"user_tz":-540,"elapsed":7,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["pos_encoding = positional_encoding(50, 512)\n","print(pos_encoding.shape)\n","\n","plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n","plt.xlabel(\"Depth\")\n","plt.xlim((0, 512))\n","plt.ylabel(\"Position\")\n","plt.colorbar()\n","plt.show()"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 50, 512)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"aNQHsYO9-qD6"},"source":["단어 임베딩 + 포지셔널 임베딩 클래스 구현  \n","주의할 점은 포지셔널 단어임베딩 * sqrt(임베딩 차원), 즉 루트가 곱해져야함  \n","위치 임베딩은 단순히 위치만 나타내기 때문에, 가중치가 단어 임베딩보단 적어야 신경망이 잘 학습됨"]},{"cell_type":"code","metadata":{"id":"Mg5gN7cEr8m2","executionInfo":{"status":"ok","timestamp":1675747660355,"user_tz":-540,"elapsed":513,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["class TransformerEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, d_model, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model # 하나의 단어가 d_model의 차원으로 인코딩 됨\n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","     # vocab_size는 tokenizer 내부 vocab.txt의 사이즈\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model) # 포지셔널 인코딩\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate) # 드롭아웃 설정\n","    \n","\n","  def call(self, x, training):\n","    # 최초 x의 shape = (batch_size, seq_len)\n","    seq_len = tf.shape(x)[1]\n","    out = self.embedding(x) # shape : (batch_size, input_seq_len, d_model)\n","    out = out * tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # x에 sqrt(d_model) 만큼을 곱해주냐면, 임베딩 벡터보다 포지셔널 인코딩 임베딩 벡터의 영향력을 줄이기 위해서임\n","                                                            # 포지셔널 인코딩은 순서만을 의미하기 때문에 임베딩 벡터보다 영향력이 적어야 이치에 맞음\n","    out = out + self.pos_encoding[:,:seq_len,:]\n","    out = self.dropout(out, training=training)\n","    \n","\n","    return out # shape : (batch_size, input_seq_len, d_model)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyuUIfwj9nuo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675747909128,"user_tz":-540,"elapsed":480,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"5eecf236-97d9-4b6b-beab-f5767b836a96"},"source":["x = np.float32(np.random.uniform(size=(1,40))) # 문장 길이 40\n","Embedder = TransformerEmbedding(512, tokenizer_en.vocab_size+2, 10000)\n","embedded = Embedder(x, False)\n","print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[-0.5484167   0.00309396 -0.31679618 ...  1.7556027   0.03698184\n","    0.21782684]\n","  [ 0.29305428 -0.45660377  0.50506    ...  1.7556027   0.0370855\n","    0.21782684]\n","  [ 0.36088073 -1.4130529   0.61961854 ...  1.7556027   0.03718916\n","    0.21782684]\n","  ...\n","  [-1.1919549  -0.23149198 -1.2233138  ...  1.7555947   0.04081737\n","    0.21781951]\n","  [-0.2520481  -0.04183239 -1.180196   ...  1.7555944   0.04092103\n","    0.2178191 ]\n","  [ 0.4153787  -0.7302631  -0.39402786 ...  1.755594    0.04102469\n","    0.21781868]]], shape=(1, 40, 512), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"QFL_iOsYBpYu"},"source":["# 스케일드 닷 프로덕트 어텐션\n","문장이 셀프 어텐션 되어서 어텐션 값과, 소프트맥스 함수를 출력하는 함수를 만들고자 합니다. scaled라는 의미는, 루트(단어의 차원 512)만큼 어텐션 값에서 나눠져 스케일링이 되기 때문에 스케일드 닷 프로덕트 어텐션이라는 이름이 붙여진 것입니다.  \n","![Imgur](https://i.imgur.com/9fmQJl9.png)  \n","제 깃허브에 올린 **심화1_어텐션의 근본적인 이해** 에서 어텐션 부분과 다른 점이 거의 없으니 복습하시면 됩니다.  \n","mask를 True로 설정하면 소프트맥스 아웃풋에서, 마스크 된 부분은 0으로 바뀌게 됩니다. 왜냐면 -1e9는 상당히 큰 값인데, e^(-1e9)는 0에 수렴하기 때문입니다.  \n","왜 트랜스포머에 마스크가 들어가는 지는 두 가지로 말씀드리겠습니다. **1) 인풋의 길이를 신경망 학습을 위해 일정한 길이로 맞추다 보면, 원래 문장의 길이를 초과하는 만큼은 패딩이 됩니다. 그 패딩한 부분을 어텐션 연산에 참여시키지 않기 위해 마스크를 사용하는 것입니다.**  \n","**2) Seq2Seq같은 기계 번역을 할 때에는 인코딩 부분과 단어 일부로 다음 단어를 예측하기 때문에, 단어 전체를 훈련하지 않고 일부분만 훈련하는 것이 논리에 맞습니다. 따라서 mask로 훈련에 필요하지 않은 부분은 0으로 바꿔주게 됩니다.**\n"]},{"cell_type":"markdown","metadata":{"id":"n8II3gNaw1K_"},"source":["문장들이 임베딩되면 인풋의 차원은 (batch_size, seq_len, d_model)입니다.  \n","scaled_dot_product_attention 이후의 차원 또한 (batch_size, seq_len, d_model)입니다.  \n","**즉 인풋과 아웃풋의 사이즈가 동일하게 됩니다.**  \n","\n","따라서 scaled_dot_product_attention의 결과는 단어들 간의 연관성을 학습한다고 이해하시면 되겠습니다."]},{"cell_type":"code","metadata":{"id":"s-NM-LwEA9FI","executionInfo":{"status":"ok","timestamp":1675748847538,"user_tz":-540,"elapsed":977,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["def scaled_dot_product_attention(q, k, v, mask=None):\n","  # q shape : (batch_size, seq_len, d_model)\n","  # k shape : (batch_size, seq_len, d_model)\n","  # v shape : (batch_size, seq_len, d_model)\n","  matmul_qk = tf.matmul(q, k, transpose_b = True)\n","  #matmul_qk shape : (batch_size, seq_len, seq_len)                                                \n","\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # scaled_attetion_logits shape : (batch_size, seq_len, seq_len)\n","\n","  if mask is not None:\n","    scaled_attention_logits = scaled_attention_logits + (mask * -1e9)\n","\n","  softmax = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","  # softmax shape : (batch_size, seq_len, seq_len)\n","\n","  output = tf.matmul(softmax, v)\n","\n","  # output(attention_value) shape : (batch_size, seq_len, d_model)\n","  # 즉 처음 입력 차원인 (batch_size, seq_len, d_model) 차원을 아웃풋으로 반환\n","\n","  return output, softmax"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"9hEWUwCDLXTj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675748857256,"user_tz":-540,"elapsed":2801,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"e3b6942a-2b9e-476c-f98b-ff0cbff56876"},"source":["q = tf.cast(np.random.uniform(size=(1,2,512)), dtype=tf.float32)\n","k = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n","v = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n","scaled_dot_product_attention(q,k,v)"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(1, 2, 512), dtype=float32, numpy=\n"," array([[[0.4557653 , 0.560415  , 0.54242533, ..., 0.47352362,\n","          0.54639184, 0.38772118],\n","         [0.44678533, 0.5727357 , 0.5380274 , ..., 0.4890948 ,\n","          0.5451081 , 0.40459323]]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 2, 7), dtype=float32, numpy=\n"," array([[[0.14637142, 0.13290583, 0.13682967, 0.11283391, 0.15703452,\n","          0.17080767, 0.14321697],\n","         [0.13575438, 0.14492726, 0.15737596, 0.13146915, 0.15412728,\n","          0.13943662, 0.13690943]]], dtype=float32)>)"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"9SBCCD7ixP_u"},"source":["# 멀티 헤드 어텐션 정의\n","멀티 헤드 어텐션은 전체 어텐션을 분리하여 병렬적으로 어텐션을 수행하는 기법입니다.  \n","즉 (batch_size, 50, 64*8) 의 텐서가 있다면 이것을 (batch_size, 50, 64) 의 8개의 텐서로 나눈다음에 개별적으로 어텐션을 수행하고, 다시 (batch_size, 50, 64*8)의 텐서로 concat(합치는) 하게 됩니다.  \n","이렇게 하는 이유는, 깊은 차원을 한번에 어텐션을 수행하는 것보다, 병렬로 각각 수행하는 것이 더 심도있는 언어들간의 관계를 학습할 수 있기 때문입니다."]},{"cell_type":"code","metadata":{"id":"sCnRYvoWGoj1","executionInfo":{"status":"ok","timestamp":1675749687788,"user_tz":-540,"elapsed":1063,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super().__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","\n","    self.dense = tf.keras.layers.Dense(d_model)\n","\n","  def split_heads(self, x, batch_size):\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0,2,1,3])\n","\n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","\n","    q = self.wq(q)\n","    k = self.wk(k)\n","    v = self.wv(v)\n","\n","    q = self.split_heads(q, batch_size)\n","    k = self.split_heads(k, batch_size)\n","    v = self.split_heads(v, batch_size)\n","\n","\n","    attention_weights, softmax = scaled_dot_product_attention(q, k, v, mask)\n","\n","    scaled_attention = tf.transpose(attention_weights, perm=[0,2,1,3])\n","\n","    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","    output = self.dense(concat_attention)\n","\n","    return output, softmax"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OM-vtx-VJXw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675749698156,"user_tz":-540,"elapsed":540,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"797db139-0ac9-4f20-8201-a1eb94ea2a66"},"source":["q = tf.cast(np.random.uniform(size=(1,2,512)), dtype=tf.float32)\n","k = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n","v = tf.cast(np.random.uniform(size=(1,7,512)), dtype=tf.float32)\n","temp_mha = MultiHeadAttention(512, 8)\n","encoder_output, _ = temp_mha(v,k,q, mask=None)\n","print(encoder_output)"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[-0.04296089  0.4174242  -0.04100064 ...  0.10953632 -1.3755398\n","   -0.29621586]\n","  [-0.03043575  0.40808594 -0.04436496 ...  0.10540938 -1.3548124\n","   -0.29027122]]], shape=(1, 2, 512), dtype=float32)\n"]}]},{"cell_type":"markdown","metadata":{"id":"bsbTtqHi3vTN"},"source":["# 포인트와이즈 피드 포워드 네트워크 정의\n","Pointwise Feed Forward 네트워크에서는 인코더의 출력에서 512개의 차원이 2048차원까지 확장되고,  \n","다시 512개의 차원으로 압축됩니다."]},{"cell_type":"code","metadata":{"id":"ZeXomoz44N5s","executionInfo":{"status":"ok","timestamp":1675749923620,"user_tz":-540,"elapsed":470,"user":{"displayName":"노혜영","userId":"02526346238893760995"}}},"source":["class Pointwise_FeedForward_Network(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.dff = dff\n","\n","    self.middle = tf.keras.layers.Dense(dff, activation='relu')\n","    self.out = tf.keras.layers.Dense(d_model)\n","\n","  def call(self, x):\n","    middle = self.middle(x) # middle shape : (batch_size, seq_len, dff)\n","    out = self.out(middle) # out shape : (batch_size, seq_len, d_model)\n","    return out"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqtcgn2x6YkB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675749925839,"user_tz":-540,"elapsed":6,"user":{"displayName":"노혜영","userId":"02526346238893760995"}},"outputId":"b40ca7d7-6bb6-4e77-9a73-93fbefefa0e0"},"source":["sample_PFFN = Pointwise_FeedForward_Network(512, 2048)\n","sample_PFFN(encoder_output)"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 512), dtype=float32, numpy=\n","array([[[-0.2563562 , -0.22325876, -0.32178918, ..., -0.16631718,\n","          0.17953217,  0.19073486],\n","        [-0.25964034, -0.22173429, -0.3199656 , ..., -0.1781463 ,\n","          0.18642169,  0.19793534]]], dtype=float32)>"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"jbkyN8bq7EYT"},"source":["# 인코더, 디코더 정의\n","지금까지 임베딩 -> 멀티 헤드 어텐션 -> 포인트와이즈 피드 포워드 네트워크까지 살펴 보았습니다.  \n","트랜스포머에서의 인코딩은 (멀티헤드어텐션 + 포인트와이즈 피드 포워드 네트워크)를 층층이 쌓은 것입니다. 따라서 방금 공부했던 멀티헤드 어텐션과 포인트와이즈 피드 포워드 네트워크를 겹겹이 쌓아서, 인코더층을 쌓는 것입니다.  \n","\n","인코더 레이어를 정의해서 멀티헤드 어텐션과 포인트와이즈 피드 포워드 네트워크를 합쳐 보도록 하겠습니다. \n","\n","단어 임베딩 벡터(단어 임베딩+위치 임베딩)가 -> 1. 멀티헤드어텐션  -> 2. Residual Network를 거쳐 원래 input과 멀티헤드어텐션의 합이 출력 -> 3. 포인트와이즈 피드포워드 네트워크 를 거치고, -> 4. Residual Network를 거쳐서 원래의 인풋과 포인트와이즈 피드포워드 네트워크의 합이 출력됨  \n","![Imgur](https://i.imgur.com/w4n19Rs.png)"]},{"cell_type":"code","metadata":{"id":"SAf18XXu6kB3"},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super().__init__()\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = Pointwise_FeedForward_Network(d_model, dff)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","  def call(self, x, training, mask=None):\n","    # x : 위치 임베딩 + 단어 임베딩 된 인코딩의 인풋\n","    attn_output, _ = self.mha(x, x, x, mask) \n","    # 멀티헤드 어텐션\n","    # attn_output shape : (batch_size, input_seq_len, d_model)\n","\n","    attn_output = self.dropout1(attn_output, training=training)\n","\n","    out1 = self.layernorm1(x + attn_output) # Residual Network 거침, 레이어 노멀레이제이션을 통한 값 평준화\n","\n","    ffn_output = self.ffn(out1) # ffn_output_shape : (batch_size, input_seq_len, d_model), 포인트와이즈 피드포워드 네트워크\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","\n","    out2 = self.layernorm2(out1 + ffn_output)   # Residual Network 거침\n","                                                # out2 shape : (batch_size, input_seq_len, d_model)\n","\n","    return out2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O7omwGh--4fv"},"source":["# 임베딩\n","x = np.float32(np.random.uniform(size=(1,40))) # 문장 길이 40\n","Embedder = TransformerEmbedding(512, tokenizer_en.vocab_size+2, 10000)\n","embedded = Embedder(x, False)\n","print(embedded) # 문장이 위치 임베딩 + 포지션 임베딩\n","#인코더\n","sample_encoder = EncoderLayer(d_model=512, num_heads=8, dff=2048, rate=0.1)\n","sample_encoding = sample_encoder(embedded, training=None, mask=None)\n","print(sample_encoding)\n","#최종출력\n","print(\"Encoded 차원 :\", sample_encoding.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F76815Y-BDZ8"},"source":["디코더를 정의하도록 하겠습니다.  \n","![Imgur](https://i.imgur.com/kGTfPr8.png)\n","\n","디코더는 인코더랑 유사하지만, 구조가 약간 다릅니다. \n","이번 Seq2Seq는 포르투갈어를 영어로 바꾸는 문제입니다.  디코더에서는 \n","두단계의 멀티 헤드 어텐션 구조를 거치는데, **첫번째 멀티 헤드 어텐션은**, **영어문장과 영어문장의 셀프 어텐션을 하여**, 영어 문장간의 관계를 배우게 됩니다.  \n","두번째 멀티 헤드 어텐션은 **포르투갈어가 인코딩 된 것과**, **영어 문장간의 셀프** **어텐션된 결과를 다시 어텐션 해서 포르투갈 어와 영어의 관계를 학습하게 됩니다.**  \n","\n","포르투갈어가 암호화된 것과, 영어 문장 한단어 한단어를 보면서 다음 단어를 예측하게 되기 때문에, look_ahead_mask를 사용하게 됩니다.  \n","만약 영어 문장이 (I love you) 로 이루어져 있다면, look_ahead_mask를 사용하면,  \n","(I, 0, 0) -> Love 예측, (I love, 0) -> You 예측, (I love you) -> 단어의 끝인 [SEP] 예측을 합니다.   \n","**즉 look_ahead_mask는 다음 단어를 예측할 때, 전에 있던 단어만으로 예측할수 있도록 앞에 있는 단어는 가리는 것입니다.**\n","  \n","  이러한 역할을 가능하게 하는 mask가 look_ahead_mask 입니다."]},{"cell_type":"markdown","metadata":{"id":"TxwEGGzZ30eh"},"source":["look_ahead_mask를 알아보겠습니다.**(매우 중요)**  \n","참고로 패딩은 1로 하겠습니다. 왜냐하면 어텐션 부분에서 mask * (-1e9)를 하는데, 패딩이 1이어야 -1e9가 곱해져서 상당히 음수로 큰 수가 되는 것이고, 이게 소프트 맥스에 들어가면 0이 되기 때문입니다.(지수함수라 지수함수에 -음수는 0으로 수렴)  \n","![Imgur](https://i.imgur.com/eLAlzji.png)  \n","![Imgur](https://i.imgur.com/gAVenk0.png)  \n","![Imgur](https://i.imgur.com/hsZ6dGs.png)"]},{"cell_type":"code","metadata":{"id":"PGtYNoL23oIR"},"source":["# 상삼각행렬 만들기\n","tf.linalg.band_part(tf.ones((10, 10)), -1, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gs3HDOex3rnK"},"source":["temp_mask = 1 - tf.linalg.band_part(tf.ones((40, 40)), -1, 0)\n","print(temp_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhYWwxQo373G"},"source":["# 예제 문장 (1, 40) 즉, 1문장, 40개의 단어를 가짐\n","example_sentence = np.hstack([np.random.randint(20, size=10), np.zeros(30)])[np.newaxis, :]\n","print(example_sentence) # 예제 문장\n","example_sentence = tf.cast(tf.math.equal(example_sentence, 0), dtype=tf.float32)\n","print(example_sentence) # 패딩 된 것(문장에서 0이 아닌 부분은 0으로, 0인 부분은 1로)\n","example_sentence = example_sentence[:, tf.newaxis, tf.newaxis, :] # 차원 변경\n","print(example_sentence)\n","\n","look_ahead_mask = tf.maximum(temp_mask, example_sentence) # 상삼각행렬과 example sentence를 비교해가며 최대값만 취해서 패딩을 1로 처리함\n","# look ahead mask\n","print(look_ahead_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uy3HuPbQ2_wJ"},"source":["# look_ahead_mask 알아보기\n","def create_look_ahead_mask(size):\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","  return mask\n","  \n","def create_masks(tar):\n","  temp_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","  \n","  \n","  reverse_tar = tf.cast(tf.math.equal(tar, 0), dtype=tf.float32)\n","  reverse_tar = reverse_tar[:,tf.newaxis,tf.newaxis,:]\n","  look_ahead_mask = tf.maximum(reverse_tar, temp_mask)\n","\n","\n","  return look_ahead_mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZYtaJVW6Q4K"},"source":["또한 패딩 마스크를 두어서, 패딩인 부분은 1으로 처리하겠습니다."]},{"cell_type":"code","metadata":{"id":"N47qF-CZ6m26"},"source":["def create_padding_mask(seq):\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6c7E0716uUj"},"source":["example_sentence = np.hstack([np.random.randint(20, size=10), np.zeros(30)])[np.newaxis, :]\n","# 패딩 되기 전\n","print(example_sentence)\n","# 패딩 된 후\n","print(create_padding_mask(example_sentence))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vr-x36BB_ekk"},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super().__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","    \n","    self.ffn = Pointwise_FeedForward_Network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","\n","\n","  def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n","    # x : 훈련 과정에서는 Seq2Seq에서 번역이 될 문장이 입력됨,\n","    # x : 추론 과정에서는 과거의 단어가 입력됨\n","    # enc_output : 인코더의 출력\n","    # padding_mask : 멀티 헤드 어텐션에 필요한 정보만 남기고 나머지는 패딩 처리\n","    # look_ahead_mask : 위에 설명\n","    # enc_output_shape == (batch_size, input_seq_len, d_model)\n","\n","    #### 첫번째 멀티 헤드 어텐션 파트임 ####\n","    #### 첫번째 멀티 헤드 어텐션은, 인코더와의 결합 없이 번역이 될 문장끼리만 어텐션을 함 ####\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","    out1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(out1 + x)\n","    \n","    #### 두번째 멀티 헤드 어텐션 파트임 ####\n","    #### 두번째 멀티 헤드 어텐션 파트는 enc_output에서 인코더와(포르투갈어), out1(영어문장으로만 셀프어텐션을 한 것)\n","    #### 이 다시 멀티 헤드 어텐션 과정을 거치게 됨\n","    #### 다시 상기하자면, 이번 과제는 포르투갈 어를 영어로 번역하는 것임\n","    attn2, attn_weights_block2 = self.mha2(\n","        enc_output, enc_output, out1, padding_mask)\n","    out2 = self.dropout2(attn2, training=training)\n","    out2 = self.layernorm2(out2 + out1) # (batch_size, target_seq_len, d_model)\n","    \n","\n","    ffn_output = self.ffn(out2)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n","    \n","\n","    return out3, attn_weights_block1, attn_weights_block2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kk9I7NdJNMN0"},"source":["sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(embedded, sample_encoding, False, None, None)\n","print(sample_decoder_layer_output)\n","print(sample_decoder_layer_output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JwKQPfQiQc_r"},"source":["이제 여러 층의 인코더를 쌓는 Encoder Class를 정의해보도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"c7WJs-lXOXtS"},"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)] # 인코더를 쌓아서 층을 만듦\n","\n","\n","  def call(self, x, training, mask):\n","    # 인풋은 타겟 임베딩 + 포지셔닝 임베딩\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training, mask)\n","\n","    return x # 출력 모양 : (batch_size, input_seq_len, d_model), 인코더의 층을 출력으로 내보냄"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfRtgnkuy578"},"source":["Encoder_layer = Encoder(6, 512, 8, 2048) #6층, 512차원의 단어 임베딩, 8개의 병렬 멀티 헤드 어텐션의 인코더\n","# embedded : 위치 임베딩 + 단어 임베딩\n","Encoded = Encoder_layer(embedded, False, None)\n","print(Encoded, Encoded.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQnvGLCzRmZ7"},"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","\n","  def call(self, x, enc_output, training, padding_mask, look_ahead_mask):\n","    attention_weights = {}\n","\n","    for i in range(self.num_layers):\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training, padding_mask, look_ahead_mask)\n","\n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","\n","    return x, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovF60mjeTnfu"},"source":["# 위치 임베딩 + 포지셔널 임베딩\n","embedded\n","#인코더 아웃풋 \n","Encoded\n","\n","# 디코더의 위치+포지셔널 임베딩(Teaching Force 과정이라 디코더 부분에 타겟(영어)도 넣어줌)\n","target_embedder = TransformerEmbedding(d_model=512, input_vocab_size=tokenizer_en.vocab_size, maximum_position_encoding=512, dropout_rate=0.1)\n","target_embedding = target_embedder(tf.cast(np.random.uniform(size=(1,40)), dtype=tf.float32), True)\n","\n","# 6층 디코더\n","Decoder_layer = Decoder(num_layers=6, d_model=512, num_heads=8, dff=2048)\n","\n","Decoded, _ = Decoder_layer(target_embedding, Encoded, False, None, None) # Decoded에서 인코더와 디코더의 정보 결합\n","print(Decoded, Decoded.shape)\n","#최종출력\n","print(\"6층 Decoder 출력 :\", sample_encoding.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"03BBwaxOUPbJ"},"source":["# 임베딩 + 인코딩 + 디코딩을 결합하는 Transformer Class 정의  \n","최종적으로 지금까지 배웠던 임베딩, 인코딩, 디코딩을 결합하는 Transformer Class를 정의하겠습니다."]},{"cell_type":"code","metadata":{"id":"cgoRro-QUE3G"},"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","    \n","    # num_layers : 인코딩, 디코딩을 몇 층으로 할 지\n","    # d_model : 임베딩의 차원\n","    # num_heads : 병렬로 어텐션을 수행할 멀티 헤드 어텐션의 개수\n","    # dff : 포인트와이즈 피드포워드 네트워크에서 몇 차원의 연산이 이루어 질 지\n","    # input_vocab_size : 본 문제는 포르투갈어를 영어로 번역하는 문제이며, 포르투갈어 토크나이저의 총 단어수를 뜻함(처음 도입부에서 만들었음)\n","    # target_vocab_size : 영어 토크나이저의 총 단어수를 뜻함(위와 마찬가지)\n","    # pe_input : 별로 중요한 것은 아니지만, 위치 임베딩 할 때 위치 임베딩의 길이의 상한을 뜻함(포르투갈어)\n","    # pe_target : 위치 임베딩의 상한(영어)\n","    super().__init__()\n","    \n","    self.input_embedder = TransformerEmbedding(d_model, input_vocab_size, pe_input, rate) # 포르투갈어 임베딩\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, rate) # x층 인코더\n","\n","    self.target_embedder = TransformerEmbedding(d_model, target_vocab_size, pe_target, rate) # 영어 임베딩\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, rate) # x층 디코더\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size) # 최종 출력 decoder (영어 단어의 수), 우리가 맞추려는 것은 영어 단어의 인덱스이므로..\n","\n","  def call(self, inp, tar, training):\n","    # inp : 포르투갈어\n","    # tar : 영어\n","\n","    \n","    enc_mask = create_padding_mask(inp) # 인코더 패딩\n","    dec_mask = create_padding_mask(inp) # 디코더 패딩\n","    look_ahead_mask = create_masks(tar) # 디코더에 들어갈 look_ahead_mask 정의\n","\n","    inp_embedding = self.input_embedder(inp) # 인코더 임베딩 정의\n","    enc_output = self.encoder(inp_embedding, training, enc_mask) # 인코더 아웃풋(디코더와 결합되게 됨)\n","\n","    tar_embedding = self.target_embedder(tar) # 디코더 임베딩 정의\n","   \n","    dec_output, attention_weights = self.decoder(tar_embedding, enc_output, training, dec_mask, look_ahead_mask)\n","    \n","    final_output = self.final_layer(dec_output) # 최종 영어 단어를 예측하는 아웃풋 정의\n","\n","    return final_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4hwFuX2H-df4"},"source":["# 트랜스포머 테스트하기\n","sample_transformer = Transformer(6, 512, 8, 2048, tokenizer_pt.vocab_size + 2, tokenizer_en.vocab_size + 2, 10000, 10000)\n","inp = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n","tar = tf.cast(np.random.randint(100,size=40)[np.newaxis, :], dtype=tf.int32)\n","transformer = sample_transformer(inp, tar, False)\n","print(transformer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0LuW2OLQ_LC3"},"source":["#하이퍼파라미터 설정하기\n","테스트를 위해서 층을 가볍게 쌓아보도록 하겠습니다."]},{"cell_type":"code","metadata":{"id":"3IBl1m3T_KdU"},"source":["num_layers = 4    # 4층 인코더, 디코더 쌓기\n","d_model = 128   # 단어의 임베딩 차원을 128로\n","dff = 512  # 포인트와이즈 피드포워드 네트워크의 일시적인 차원을 512\n","num_heads = 8 # 멀티 헤드 어텐션을 8개로 병렬 처리\n","SEQ_LEN = 40\n","\n","input_vocab_size = tokenizer_pt.vocab_size + 2\n","target_vocab_size = tokenizer_en.vocab_size + 2\n","dropout_rate = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oJlCBwNE_Sex"},"source":["# 옵티마이저 설정하기\n","옵티마이저는 논문에 따라서 성능이 좋았다는 옵티마이저를 복사 붙여넣기 하였습니다."]},{"cell_type":"code","metadata":{"id":"wH6O3Gvs_R0O"},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n","\n","learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZemqrgPw_bPe"},"source":["# Loss 함수 설정하기\n","loss 함수 또한 중요한 부분인데, transformer에서는 패딩되는 부분을 Loss를 계산할 때 연산하지 않겠습니다."]},{"cell_type":"code","metadata":{"id":"vl-ogg3D_eru"},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') #from_logits=True로 하면 Dense 이후 softmax layer 값 출력\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0)) # 예를 들어서 실제 자료(0은 패딩)가 [1,2,3,4,5,0,0,0,0,0] 이라면 [0,0,0,0,0,1,1,1,1,1]로 바꿔 줌\n","                                                     # 이후 tf.math.logical_not을 활용해서 [True,True,True,True,True,False,False,False,False,False]으로 바꿔 줌\n","  loss_ = loss_object(real, pred) # loss_는 패딩을 고려하지 않은 loss 값\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype) # [True,True,True,True,True,False,False,False,False,False]를 [1,1,1,1,1,0,0,0,0,0] 으로 바꿔 줌\n","  loss_ *= mask # loss에 mask를 곱해서, 패딩인 부분은 0처리 해줌\n","\n","  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6zZ0hEBSD5ka"},"source":["# 모델 훈련"]},{"cell_type":"code","metadata":{"id":"Z2GySrPlEx2l"},"source":["transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=10000, \n","                          pe_target=10000,\n","                          rate=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k07jNkQIw9N6"},"source":["# 인풋, 아웃풋의 텐셔 shape 정의\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","# tf.function을 사용하면 그래프를 미리 컴파일 하기 때문에 속도가 상당히 빠름\n","# 같은 GPU여도 케라스에 비해서 체감상 7~8배 정도의 차이가 나는 것 같음\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  with tf.GradientTape() as tape:\n","    predictions = transformer(inp, tar_inp, True)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Iq2uReVFS1J"},"source":["# 저장할 체크포인트 지정\n","checkpoint_path = \"./\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHAeCJP-xZCu"},"source":["import time\n","# 20 에포크 훈련\n","for epoch in range(20):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  # input : 포루투갈어, tar : 영어\n","  for (batch, (inp, tar)) in enumerate(train_dataset):\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"45sJJKmdL8u-"},"source":["# 평가  \n","![Imgur](https://i.imgur.com/cUjg18g.png)\n","평가는 훈련과는 다르게 진행됩니다.  \n","번역할 포르투갈어는 인코더 레이어를 거쳐 인코딩이 되고,  \n","디코더에는 영어 문장을 넣지 않고, 영어 문장의 시작 토큰만 디코더의 인풋으로 들어가게 됩니다.  \n","그러면 인코딩 된 것과 + 시작 토큰을 활용해서 다음 단어를 예측하고,  \n","인코딩 된 것 + 시작 토큰 + 전에 예측된 단어를 활용해서 다음 단어를 예측하는 방식입니다. \n","  \n","그림에서는 bos가 시작 토큰입니다.\n","![Imgur](https://i.imgur.com/F6QseH6.png)"]},{"cell_type":"code","metadata":{"id":"fdaL7LLfGzaQ"},"source":["def evaluate(inp_sentence):\n","  # inp_sentence : 문자 (string)\n","  start_token = [tokenizer_pt.vocab_size] # 포르투갈어의 시작 토큰\n","  end_token = [tokenizer_pt.vocab_size + 1] # 포르투갈어의 끝 토큰\n","  \n","  # 시작 토큰 + 포르투갈 어 + 끝 토큰\n","  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n","  encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","  # 디코더의 인풋은 영어 문장의 시작 토큰만 들어감\n","  decoder_input = [tokenizer_en.vocab_size]\n","  output = tf.expand_dims(decoder_input, 0)\n","  \n","  for i in range(MAX_LENGTH):\n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions = transformer(encoder_input, output, False)\n","    \n","    # 예측 결과에서 마지막 부분만 추출\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","    # 만약에 예측된 영어 단어가 영어의 끝 토큰에 해당한다면 예측을 끝냄\n","    if predicted_id == tokenizer_en.vocab_size+1:\n","      return tf.squeeze(output, axis=0)\n","    \n","    # 예측된 단어를 전 단어와 결합하여 다음 예측에 써먹음\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ECK0XFzCHBxv"},"source":["def translate(sentence):\n","  result= evaluate(sentence)\n","  \n","  predicted_sentence = tokenizer_en.decode([i for i in result \n","                                            if i < tokenizer_en.vocab_size])  \n","\n","  print('Input: {}'.format(sentence))\n","  print('Predicted translation: {}'.format(predicted_sentence))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fe6y5oDePZOI"},"source":["실제로 번역해보기  \n","제법 포르투갈 어를 영어 문법에 맞게 번역하는 것을 알 수 있습니다."]},{"cell_type":"code","metadata":{"id":"czjSk64HHCq5"},"source":["translate(\"este é um problema que temos que resolver.\")\n","print (\"Real translation: this is a problem we have to solve .\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WkQuQyvjHcbJ"},"source":["translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n","print (\"Real translation: and my neighboring homes heard about this idea .\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76ZizBuyPbd8"},"source":["translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n","print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29vxXk81PlbE"},"source":["translate(\"este é o primeiro livro que eu fiz.\")\n","print (\"Real translation: this is the first book i've ever done.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xn44IonrZhnV"},"source":["출처  \n","http://jalammar.github.io/illustrated-gpt2/  \n","https://d2l.ai/chapter_recurrent-modern/seq2seq.html  \n","https://www.tensorflow.org/tutorials/text/transformer\n"]}]}